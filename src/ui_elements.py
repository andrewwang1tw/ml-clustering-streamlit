import io
import json
import platform
import streamlit as st
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
from agent.langGraph_ollama import stream_graph_updates, stream_ollama_updates
import base64
import matplotlib.font_manager as fm

#-----------------------------------------------------------------------------------
# é¡¯ç¤º sidebar è¼¸å…¥å…ƒä»¶ï¼Œå›å‚³æ‰€æœ‰åƒæ•¸å€¼
#-----------------------------------------------------------------------------------
def sidebar_inputs():  
    # åœ¨ sidebar å»ºç«‹ä¸€å€‹å®¹å™¨ï¼Œè®“æŒ‰éˆ•é¡¯ç¤ºåœ¨æœ€ä¸Šé¢
    top_container = st.sidebar.container()
    run = top_container.button('ğŸš€ è¼‰å…¥ä¸¦åŸ·è¡Œåˆ†æ', key='run_button')
 
    st.sidebar.header('æŸ¥è©¢æ¢ä»¶')
    year = st.sidebar.number_input('æ°‘åœ‹å¹´ (å¹´)', min_value=100, max_value=200, value=114, key="query_year")
    month_from = st.sidebar.number_input('èµ·å§‹æœˆ (>=1)', min_value=1, max_value=12, value=1, key="query_month_from")

    st.sidebar.header('Feature é¸é …')
    last_n_months = st.sidebar.slider('æœ€è¿‘ n å€‹æœˆç‡Ÿæ”¶æœˆå¢èˆ‡å¹´å¢å‡æˆé•·', 1, 12, 3, key="feature_n_months")

    st.sidebar.header('Clustering é¸é …')
    k_min = st.sidebar.number_input('k æœ€ä½', min_value=1, max_value=10, value=1, key="k_min")
    k_max = st.sidebar.number_input('k æœ€é«˜', min_value=2, max_value=20, value=10, key="k_max")
    manual_k = st.sidebar.number_input('æ‰‹å‹•è¨­å®š k (0=è‡ªå‹•)', min_value=0, max_value=10, value=3, key="manual_k")
    
    st.sidebar.header('è³‡æ–™åº«é€£ç·š')
    server = st.sidebar.text_input('SQL Server', value='localhost', key="db_server")
    database = st.sidebar.text_input('Database', value='stock_tw', key="db_name")
    trusted = st.sidebar.checkbox('Use Trusted Connection (Windows Auth)', value=True, key="trusted_connection")

    return {
        'server': server,
        'database': database,
        'trusted': trusted,
        'year': year,
        'month_from': month_from,
        'last_n_months': last_n_months,
        'k_min': k_min,
        'k_max': k_max,
        'manual_k': manual_k,
        'run': run
    }


#-----------------------------------------------------------------------------------
# Tab 0, 
#-----------------------------------------------------------------------------------
def show_sales_data(df_raw, df_feature):
    print("\ncorr_df, Tab 1 ===>\n", df_raw)    
    
    st.write("âœï¸ **åŸå§‹æœˆç‡Ÿæ”¶è³‡æ–™**")    
    st.dataframe(df_raw, height=280)
       
    st.write("ğŸ”” **ç‰¹å¾µ**")    
    st.dataframe({
        "ç‰¹å¾µåç¨±": ["continuous_flag", "avg_mom", "std_mom", "avg_yoy", "std_yoy"],
        "èªªæ˜": [
            "ç•¶è¿‘ n å€‹æœˆç‡Ÿæ”¶æœˆå¢ç‡èˆ‡å¹´å¢ç‡å‡æˆé•·æ™‚ç‚º 1, å…¶é¤˜ç‚º 0",
            "å¹³å‡æœˆå¢ç‡",
            "æœˆå¢ç‡çš„æ¨™æº–å·®, å³æ³¢å‹•ç¨‹åº¦",
            "å¹³å‡å¹´å¢ç‡",
            "å¹´å¢ç‡çš„æ¨™æº–å·®, å³æ³¢å‹•ç¨‹åº¦"
        ]
    })
        
    st.write("ğŸ”” **åŠ å…¥æ–°ç‰¹å¾µ, ä»¥æ­¤è³‡æ–™ä½œç›¸é—œåˆ†æ**")
    st.dataframe(df_feature, height=400)
        

#-----------------------------------------------------------------------------------
# Tab 1, show_correlation_heatmap
#-----------------------------------------------------------------------------------
def show_correlation_heatmap(corr_before, corr_after, dropped=None):
    print("\ncorr_before, Tab 1 ===>\n", corr_before)
       
    option = st.selectbox("ğŸ“Š é¸æ“‡", ["Before, å»é«˜åº¦ç›¸é—œå‰", "After, å»é«˜åº¦ç›¸é—œå¾Œ"], key='select_corr_option')
    corr_df = corr_before if option.startswith("Before") else corr_after   
              
    #st.write(title)
    fig, ax = plt.subplots(figsize=(6, 6))
    sns.heatmap(corr_df, annot=False, cmap="coolwarm", center=0, ax=ax, square=True)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=8)
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=8)
    st.pyplot(fig)

    # é¡¯ç¤ºé«˜ç›¸é—œå°
    st.write("âš ï¸ é«˜ç›¸é—œç‰¹å¾µ Pairs")
    threshold = 0.9
    high_corr_pairs = []
    cols = corr_df.columns
    for i in range(len(cols)):
        for j in range(i + 1, len(cols)):
            if corr_df.iloc[i, j] > threshold:
                high_corr_pairs.append((cols[i], cols[j], round(corr_df.iloc[i, j], 3)))

    if high_corr_pairs:
        st.dataframe(pd.DataFrame(high_corr_pairs, columns=["Feature A","Feature B","Correlation"]))
    else:
        st.success("æ²’æœ‰è¶…éç›¸é—œä¿‚æ•¸é–¾å€¼çš„ç‰¹å¾µ pair âœ…")
        
    # è¢«ç§»é™¤çš„é«˜ç›¸é—œç‰¹å¾µ
    if dropped is not None:
        st.write("ğŸ—‘ï¸ è¢«ç§»é™¤çš„é«˜ç›¸é—œç‰¹å¾µ")
        st.write(dropped if dropped else "âœ… æ²’æœ‰ç‰¹å¾µè¢«ç§»é™¤")    


#-----------------------------------------------------------------------------------
# ollama_chat
#-----------------------------------------------------------------------------------
def ollama_chat(input: str):  
    with st.status("ğŸ“‚ AI è§£é‡‹ä¸­...", expanded=True) as status:       
        response = stream_ollama_updates(input)     
        if response:                                  
            st.markdown(response) 
        
        status.update(label="ğŸ“‚ AI è§£é‡‹", state="complete", expanded=True)    
       

#-----------------------------------------------------------------------------------
# Tab 2, show_elbow_plot
#-----------------------------------------------------------------------------------
def show_elbow_plot(k_min, k_max, inertias, use_k, elbow_k):  
    print("\nuse_k, Tab 2 ===>\n", use_k)
    print("\ninertias, Tab 2 ===>\n", inertias)
    
    #st.markdown('ğŸ“‰ **Elbow Plot**')    
    st.markdown(f"ğŸ“‰ **ç›®å‰åˆ†ç¾¤:** {use_k}, **æœ€ä½³åˆ†ç¾¤ (KneeLocator elbow point):** {elbow_k} ")

    # Elbow Method
    fig2, ax2 = plt.subplots(figsize=(6, 3))
    ax2.plot(range(k_min, k_max+1), inertias, marker='o')
    ax2.set_xlabel('Number of Clusters (k)')
    ax2.set_ylabel('Inertia (SSE)')
    ax2.set_title('Elbow Method')
    st.pyplot(fig2)
   
    # --- AI  ---      
    input = f"""
            Let's say, the inertias: {inertias}, is the result from MiniBatchKMeans. 
            It's the mbk.inertia_ from mbk = MiniBatchKMeans(n_clusters=kk, random_state=42, n_init=10, batch_size=256) .                
            Please explain the inertias and list the full inertias. And answer in Traditional Chinese.  
            """            
    if st.button("AI è§£é‡‹ Elbow method inertias (SSE)", key="ai_elbow_method_elbow method"):
        #with st.status("ğŸ“‚ AI è§£é‡‹ä¸­...", expanded=True) as status: 
            ollama_chat(input) 
            #status.update(label="ğŸ“‚ AI è§£é‡‹", state="complete", expanded=True) 
   
    #
    st.dataframe(pd.DataFrame(inertias, columns=["inertias, Sum of Squared Errors (SSE)"]))
  
 
#-----------------------------------------------------------------------------------
# Tab 31, show_pca
#-----------------------------------------------------------------------------------
def show_pca_3d(df_clustered, pca3, features):
    print("\ndf_clustered, Tab 31 ===>\n", df_clustered)
    print("\npca 3d, Tab 31 ===>\n", pca3)
    print("\nfeatures, Tab 31 ===>\n", features)
    
    st.write("ğŸ”µ ä¸»æˆåˆ†åˆ†æ (PCA 3D)")    
    fig4 = px.scatter_3d(df_clustered, x='PC1_3', y='PC2_3', z='PC3_3',
                         color=df_clustered['cluster'].astype(str),
                         hover_data=['stock_id_', 'stock_name_'])   
     
    fig4.update_layout(title='PCA 3D åˆ†ç¾¤', legend_title='cluster',
                       paper_bgcolor='rgba(250,250,250,1)', margin=dict(l=40, r=40, t=40, b=40))  
      
    st.plotly_chart(fig4, use_container_width=True)

    # --- å„ä¸»æˆåˆ†è®Šç•°æ¯”ä¾‹ ---    
    st.write("**å„ä¸»æˆåˆ†è®Šç•°æ¯”ä¾‹ (Explained Variance Ratio)**") 
    df = pd.DataFrame({
        "PC1": [pca3.explained_variance_ratio_[0]], 
        "PC2": [pca3.explained_variance_ratio_[1]], 
        "PC3": [pca3.explained_variance_ratio_[2]], 
        "ç¸½è§£é‡‹æ¯”ä¾‹": [sum(pca3.explained_variance_ratio_[:3])]
    })    
    styled_df = df.style.format("{:.4f}")
    st.dataframe(styled_df, hide_index=True)
   
    # --- ä¸»æˆåˆ†çµ„æˆ ---
    st.write("**ä¸»æˆåˆ†çµ„æˆ (Components)**")
    comp_df3 = pd.DataFrame(pca3.components_, columns=features, index=["PC1", "PC2", "PC3"])
    st.dataframe(comp_df3.style.format("{:.3f}"))
    print("\ncomp_df3, Tab 31 ===>\n", comp_df3)
      
    # --- AI  ---      
    input = f"""
                Please explain the 3D PCA(Principal Component Analysis) analysis with 
                Explained Variance Ratio: {df},
                Components:{comp_df3}, 
                Features as below
                continuous_flag : è¿‘å¹¾å€‹æœˆé€£çºŒç‡Ÿæ”¶æœˆå¢ç‡èˆ‡å¹´å¢ç‡å‡æˆé•·æ™‚ç‚º 1. 
                avg_mom : å¹³å‡æœˆå¢ç‡, åæ˜ å…¬å¸æˆé•·å‹•èƒ½.
                std_mom : æœˆå¢ç‡çš„æ¨™æº–å·®, åæ˜ å…¬å¸ç‡Ÿæ”¶çš„æ³¢å‹•æ€§.
                avg_yoy : å¹³å‡å¹´å¢ç‡, åæ˜ å…¬å¸æˆé•·å‹•èƒ½.
                std_yoy : å¹´å¢ç‡çš„æ¨™æº–å·®, åæ˜ å…¬å¸ç‡Ÿæ”¶çš„æ³¢å‹•æ€§.
                And answer in Traditional Chinese.
            """            
    if st.button("AI è§£é‡‹ PCA (3D)", key="ai_pca_3d"):       
        ollama_chat(input)
      
         
    st.divider()
    
#-----------------------------------------------------------------------------------
# Tab 32, show_pca
#-----------------------------------------------------------------------------------
def show_pca_2d(df_clustered, pca2, features):
    print("\ndf_clustered, Tab 32 ===>\n", df_clustered)
    print("\npca 2d, Tab 32 ===>\n", pca2)
    print("\nfeatures, Tab 32 ===>\n", features)
    
    st.write("ğŸ”µ ä¸»æˆåˆ†åˆ†æ (PCA 2D)")
    
    fig3 = px.scatter(df_clustered, x='PC1', y='PC2',
                      color=df_clustered['cluster'].astype(str),
                      hover_data=['stock_id_', 'stock_name_'])
    
    fig3.update_layout(title='PCA 2D åˆ†ç¾¤', legend_title='cluster',
                       paper_bgcolor='rgba(250,250,250,1)', margin=dict(l=40, r=40, t=40, b=40))
    
    st.plotly_chart(fig3, use_container_width=True)

    # --- å„ä¸»æˆåˆ†è®Šç•°æ¯”ä¾‹ ---
    st.write("**å„ä¸»æˆåˆ†è®Šç•°æ¯”ä¾‹ (Explained Variance Ratio)**") 
    df = pd.DataFrame({
        "PC1": [pca2.explained_variance_ratio_[0]], 
        "PC2": [pca2.explained_variance_ratio_[1]], 
        "ç¸½è§£é‡‹æ¯”ä¾‹": [sum(pca2.explained_variance_ratio_[:2])]
    })    
    styled_df = df.style.format("{:.4f}")
    st.dataframe(styled_df, hide_index=True)

    # --- ä¸»æˆåˆ†çµ„æˆ ---
    st.write("**ä¸»æˆåˆ†çµ„æˆ (Components)**")
    comp_df = pd.DataFrame(pca2.components_, columns=features, index=["PC1", "PC2"])
    st.dataframe(comp_df.style.format("{:.3f}"))
    
    # --- AI ---
    input = f"""
                Please explain the 2D PCA(Principal Component Analysis) analysis with 
                Explained Variance Ratio: {df},
                Components:{comp_df}, 
                Features as below
                continuous_flag : è¿‘å¹¾å€‹æœˆé€£çºŒç‡Ÿæ”¶æœˆå¢ç‡èˆ‡å¹´å¢ç‡å‡æˆé•·æ™‚ç‚º 1. 
                avg_mom : å¹³å‡æœˆå¢ç‡, åæ˜ å…¬å¸æˆé•·å‹•èƒ½.
                std_mom : æœˆå¢ç‡çš„æ¨™æº–å·®, åæ˜ å…¬å¸ç‡Ÿæ”¶çš„æ³¢å‹•æ€§.
                avg_yoy : å¹³å‡å¹´å¢ç‡, åæ˜ å…¬å¸æˆé•·å‹•èƒ½.
                std_yoy : å¹´å¢ç‡çš„æ¨™æº–å·®, åæ˜ å…¬å¸ç‡Ÿæ”¶çš„æ³¢å‹•æ€§.
                And answer in Traditional Chinese.
            """            
    if st.button("AI è§£é‡‹ PCA (2D)", key="ai_pca_2d"):
        ollama_chat(input)  
            
    st.divider()
    
#-----------------------------------------------------------------------------------
# Tab 41, show_cluster_summary
#-----------------------------------------------------------------------------------
def show_cluster_summary(df_clustered, features):
    print("\ndf_clustered, Tab 41 ===>\n", df_clustered)
    print("\nfeatures, Tab 41 ===>\n", features)        
    st.write('ğŸ“‹ **ç¾¤é›†ç‰¹å¾µ Summary Table**')
    
    summary = df_clustered.groupby('cluster').agg({
        'stock_id_': 'count',
        'continuous_flag': 'mean',
        'avg_mom': 'mean',
        'std_mom': 'mean',
        'avg_yoy': 'mean',
        'std_yoy': 'mean'
    }).rename(columns={'stock_id_': 'count'})
        
    # ç†±åº¦èƒŒæ™¯æ ¼å¼åŒ–        
    styled = summary.style.format({
        'count':"{:.0f}",
        'continuous_flag':"{:.0f}",
        'avg_mom': "{:.1f}",
        'std_mom': "{:.1f}",
        'avg_yoy': "{:.1f}",
        'std_yoy': "{:.1f}"
    }).background_gradient(
        cmap="RdYlGn",  # é›™å‘é¡è‰² (ç´…â†’é»ƒâ†’ç¶ )
        axis=None,      # æ•´å¼µè¡¨çµ±ä¸€é¡è‰²æ¯”ä¾‹
        vmin=-summary.abs().max().max(),  # è² åˆ°æ­£å°ç¨±
        vmax=summary.abs().max().max()
    )
    
    st.dataframe(styled)
    
    # --- AI ---
    input = f"""
                Please explain the machine learning cluster, summary as {summary} and features {features}
                Features as below
                count : the  number of the stock in the cluster.
                continuous_flag : è¿‘å¹¾å€‹æœˆçš„æ¯æœˆç‡Ÿæ”¶æœˆå¢ç‡èˆ‡å¹´å¢ç‡åŒæ™‚éƒ½æ­£æˆé•·æ™‚ç‚º 1, å¦å‰‡ 0. 
                avg_mom : å¹³å‡æœˆå¢ç‡, åæ˜ å…¬å¸æˆé•·å‹•èƒ½.
                std_mom : æœˆå¢ç‡çš„æ¨™æº–å·®, åæ˜ å…¬å¸ç‡Ÿæ”¶çš„æ³¢å‹•æ€§.
                avg_yoy : å¹³å‡å¹´å¢ç‡, åæ˜ å…¬å¸æˆé•·å‹•èƒ½.
                std_yoy : å¹´å¢ç‡çš„æ¨™æº–å·®, åæ˜ å…¬å¸ç‡Ÿæ”¶çš„æ³¢å‹•æ€§.                
                And answer in Traditional Chinese.
            """            
    if st.button("AI ç¾¤é›†ç‰¹å¾µ Summary Table", key="ai_cluster_summary"):
        ollama_chat(input)  
            
    st.divider()


#-----------------------------------------------------------------------------------
# Tab 42, show_cluster_feature_boxplots
#-----------------------------------------------------------------------------------
def show_cluster_feature_boxplots(df_clustered, last_n_months):
    print("\ndf_clustered, Tab 42 ===>\n", df_clustered)    
    st.write('ğŸ“‹ **å„ç¾¤ç‰¹å¾µå·®ç•°**')
    
    #
    fig, ax = plt.subplots(figsize=(6,3))
    sns.barplot(data=df_clustered, x='cluster', y='continuous_flag', estimator='mean', ax=ax)
    ax.set_title(f'æœ€è¿‘{last_n_months}å€‹æœˆ,æœˆå¢èˆ‡å¹´å¢åŒæ™‚æˆé•·', fontsize=10)
    ax.set_xlabel('ç¾¤é›†(cluster)', fontsize=10)
    ax.set_ylabel('æœˆå¢/å¹´å¢åŒæ™‚é€£çºŒæˆé•·', fontsize=10)
    ax.tick_params(axis='x', labelsize=8)
    ax.tick_params(axis='y', labelsize=8)
    st.pyplot(fig)

    #
    for col, title in [('avg_mom','å¹³å‡æœˆå¢æˆé•·'), ('std_mom','æœˆå¢æ¨™æº–å·®'),
                       ('avg_yoy','å¹³å‡å¹´å¢æˆé•·'), ('std_yoy','å¹´å¢æ¨™æº–å·®')]:
        fig_c, ax_c = plt.subplots(figsize=(6,3))
        sns.boxplot(data=df_clustered, x='cluster', y=col, ax=ax_c)
        ax_c.set_title(f'{title}', fontsize=10)
        ax_c.set_xlabel('ç¾¤é›†(cluster)', fontsize=10)
        ax_c.set_ylabel(f'{title}', fontsize=10)
        ax_c.tick_params(axis='x', labelsize=8)
        ax_c.tick_params(axis='y', labelsize=8)
        st.pyplot(fig_c)

#-----------------------------------------------------------------------------------
# è¼”åŠ©å‡½å¼ï¼šå–å¾—ç¾¤é›†æ¨™ç±¤åˆ—è¡¨
#-----------------------------------------------------------------------------------
def get_cluster_labels(df_clustered):
    cluster_counts = df_clustered['cluster'].value_counts().sort_index()
    cluster_labels = [f"ç¾¤ {i} ({cnt} ç­†)" for i, cnt in cluster_counts.items()]
    return cluster_counts, cluster_labels

#-----------------------------------------------------------------------------------
# Tab 5, show_cluster_details
#-----------------------------------------------------------------------------------
def show_cluster_details(df_clustered, page_size=10):    
    #st.subheader('ğŸ—“ï¸ ç¾¤é›†è©³ç´°æª¢è¦–')
    print("\ndf_clustered, Tab 5 ===>\n", df_clustered)    
        
    # --- æ¯ä¸€å€‹ cluster çš„ç­†æ•¸ ---   
    cluster_counts, cluster_labels = get_cluster_labels(df_clustered)
    col1, col2 = st.columns([2, 1])
    with col1: 
        selected = st.selectbox('ğŸ“ˆ é¸æ“‡ç¾¤é›†', options=cluster_labels, key="cluster_select_label")
    
    # --- æ‰¾å‡ºæ‰€é¸çš„ cluster ---
    idx = cluster_labels.index(selected)
    cluster_index = cluster_counts.index[idx]
    df_cluster_selected = df_clustered[df_clustered['cluster'] == cluster_index]
    print("\ndf_cluster_selected, Tab 5 ===>\n", df_cluster_selected)

    total = len(df_cluster_selected)
    total_pages = (total - 1) // page_size + 1 if total > 0 else 1         
    with col2: 
        page = st.number_input("ğŸ“ˆ é ç¢¼", min_value=1, max_value=total_pages, value=1, step=1, key="cluster_page_num")    
        
    start = (page - 1) * page_size
    end = start + page_size        
    st.write(f'ğŸ“ˆ ç¾¤ {cluster_index} (count={total}) - ç¬¬ {page}/{total_pages} é ')
    
    df = df_cluster_selected[['stock_id_','stock_name_', 
                    'continuous_flag',
                    'avg_mom','std_mom', 
                    'avg_yoy','std_yoy']].iloc[start:end].copy()    
     
    selected_rows_dict = st.dataframe(
        df,
        hide_index=True,
        on_select="rerun",
        selection_mode="single-row"        
    )   
    
    # --- æä¾›ä¸‹è¼‰è©²ç¾¤ Excel ---
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df_cluster_selected.to_excel(writer, index=False, sheet_name=f'cluster_{cluster_index}')
        
    excel_data = buffer.getvalue()
    st.download_button(
        label="ğŸ“ˆ ä¸‹è¼‰è©²ç¾¤çµæœ Excel",
        data=excel_data,
        file_name=f"cluster_{cluster_index}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
    # --- å–å¾—é¸å–åˆ°çš„è³‡æ–™, å¦‚æœæœ‰ä»»ä½•ä¸€è¡Œè¢«é¸å– ---
    selected_indices = selected_rows_dict.get('selection', {}).get('rows', [])
    if selected_indices:
        # å–å¾—è¢«é¸å–çš„åˆ—çš„ç´¢å¼•
        print("\né¸å–åˆ°çš„è³‡æ–™, selected_indices ===>\n", selected_indices, "\n")
        selected_row_index = selected_indices[0]       
        selected_row_data = df.iloc[selected_row_index]        
        print("\né¸å–åˆ°çš„è³‡æ–™m selected_row_data ===>\n", selected_row_data, "\n")
        
        # å–å¾—ç‰¹å®šæ¬„ä½çš„å€¼
        selected_id = selected_row_data['stock_id_']
        selected_name = selected_row_data['stock_name_']
        print("\nå–å¾—é¸å–åˆ°çš„è³‡æ–™ ===>\nselected_id= ", selected_id, ", selected_name= ", selected_name, "\n")
        
        # --- Use LangGraph --- 
        user_input = f"""
            Summary Taiwan stock {str(selected_id)}.TW for basic information and recent stock price, company operation and related news.             
            Include domain will be https://tw.stock.yahoo.com/ , https://www.cnyes.com/ , https://www.ctee.com.tw/ and https://money.udn.com/ .            
            If you can not find related information just say "no information found!" directly.             
            Finally, must answer in Traditional Chinese.                                              
            """  
        with st.status("ğŸŒ LangGraph æœå°‹ä¸­...", expanded=True) as status:              
            all_messages, last_msg = stream_graph_updates(user_input)                            
            if all_messages:
                status.update(label="ğŸŒ LangGraph ä»»å‹™å·²å®Œæˆï¼", state="complete", expanded=True)                      
                for message in all_messages: 
                    try:        
                        data = json.loads(message)  
                        if data:
                            with st.expander("ğŸ“‚ AI Agent é€é TavilySearch æœå°‹åˆ°çš„è³‡æ–™"):                                     
                                for result in data.get('results', []):
                                    with st.container():
                                        st.markdown(f"**[{result.get('title', 'ç„¡æ¨™é¡Œ')}]({result.get('url', '#')})**")
                                        st.markdown(f"*{result.get('content', 'ç„¡æ‘˜è¦')}*")
                                    
                    except json.JSONDecodeError:
                        # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°±ç•¶ä½œæ™®é€šæ–‡å­—é¡¯ç¤º    
                        with st.expander("ğŸ“¦ AI Agent ç¸½çµæœå°‹åˆ°çš„è³‡æ–™"):
                            st.write(message)
        
                           
#-----------------------------------------------------------------------------------
# Tab 6, show_cluster_mom_yoy
#-----------------------------------------------------------------------------------
def show_cluster_mom_yoy(df_clustered, page_size=10):
    #st.subheader('ğŸ“ˆ MoM, YoY')
    print("\ndf_clustered, Tab 6 ===>\n", df_clustered)
      
    # 
    cluster_counts, cluster_labels = get_cluster_labels(df_clustered)
    selected = st.selectbox('é¸æ“‡ç¾¤é›†', options=cluster_labels, key="cluster_select_label2")
    
    # æ‰¾å‡ºæ‰€é¸çš„ cluster
    idx = cluster_labels.index(selected)
    cluster_index = cluster_counts.index[idx]
    cluster_df = df_clustered[df_clustered['cluster'] == cluster_index]
    
    # MoM æ™‚åº
    mom_cols_all = sorted([c for c in df_clustered.columns if c.startswith('æœˆå¢_')])
    if len(cluster_df) > 0 and mom_cols_all:
        st.write('ğŸ“ˆ **MoM æ™‚é–“åºåˆ—**')
        mom_data = cluster_df[mom_cols_all].T
        mom_data.columns = cluster_df['stock_id_'].astype(str) + ' ' + cluster_df['stock_name_'].astype(str)
        st.line_chart(mom_data)
        
    # YoY æ™‚åº
    yoy_cols_all = sorted([c for c in df_clustered.columns if c.startswith('å¹´å¢_')])
    if len(cluster_df) > 0 and yoy_cols_all:
        st.write('ğŸ“ˆ **YoY æ™‚é–“åºåˆ—**')
        yoy_data = cluster_df[yoy_cols_all].T
        yoy_data.columns = cluster_df['stock_id_'].astype(str) + ' ' + cluster_df['stock_name_'].astype(str)
        st.line_chart(yoy_data)


#-----------------------------------------------------------------------------------
# set_font ä¸­æ–‡
#-----------------------------------------------------------------------------------       
def set_font():       
    # sns.set_theme(style="whitegrid")  # ä½ ä¹Ÿå¯ä»¥é¸ whitegrid, darkgrid, ticks ç­‰    
    # matplotlib.rcParams['axes.unicode_minus'] = False
    
    # if platform.system() == "Windows":
    #     matplotlib.rcParams['font.family'] = 'Microsoft JhengHei'
    # elif platform.system() == "Darwin":
    #     matplotlib.rcParams['font.family'] = 'Heiti TC'
    # else:
    #     matplotlib.rcParams['font.family'] = 'Noto Sans CJK TC'  
    
    # Force Matplotlib to rebuild its font cache to detect newly installed fonts.
    fm.rebuild()

    sns.set_theme(style="whitegrid")    
    matplotlib.rcParams['axes.unicode_minus'] = False
    
    # Check the operating system
    if platform.system() == "Windows":
        matplotlib.rcParams['font.family'] = 'Microsoft JhengHei'
    elif platform.system() == "Darwin":
        matplotlib.rcParams['font.family'] = 'Heiti TC'
    else:  # Assumed to be Linux, e.g., Streamlit Cloud
        # This will now correctly find the font because it's been installed and the cache is rebuilt.
        matplotlib.rcParams['font.family'] = 'Noto Sans CJK TC'
    
#-----------------------------------------------------------------------------------
# set_layout
#-----------------------------------------------------------------------------------        
def set_layout():
    st.set_page_config(
        layout='centered', 
        page_title='ğŸ“ˆ ç‡Ÿæ”¶åˆ†ç¾¤èˆ‡ PCA åˆ†æ (Streamlit)'
    )  
    
    # æµ®æ°´å°çš„ CSS æ¨£å¼
    watermark_css = """
    <style>
    .watermark {
        position: fixed;
        top: 2%;
        left: 45%;
        #transform: translate(-50%, -50%) rotate(-40deg);
        font-size: 5rem;
        font-weight: bold;
        color: rgba(128, 128, 128, 0.1); /* ç°è‰²çš„é€æ˜åº¦ */
        user-select: none;
        pointer-events: none;
        z-index: 1000;
    }
    .watermark-img {{
        width: 200px; /* åœ–ç‰‡å¤§å° */
        height: 100px;
    }}
    </style>
    """  
    
    # å¯«å…¥ CSS, åŠ å…¥æµ®æ°´å°æ–‡å­—
    st.markdown(watermark_css, unsafe_allow_html=True)   
    st.markdown('<div class="watermark">Andrew Wang</div>', unsafe_allow_html=True)
    
    # # åŠ å…¥ Image
    # image_path = "img/1.png"
    # def get_base64_image(path):
    #     with open(path, "rb") as image_file:
    #         return base64.b64encode(image_file.read()).decode()
    
    # image_b64 = get_base64_image(image_path)    
    # st.markdown(f'<div class="watermark"><img src="data:image/png;base64,{image_b64}" class="watermark-img"></div>', unsafe_allow_html=True)

